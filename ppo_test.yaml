
algorithm: PPO

stop:
    episode_reward_mean: 5000
    training_iteration: 1000
    timesteps_total: 1000000

config:
    env: godot
    env_config:
        framerate: null
        show_window: true
    framework: torch  
    lambda: 0.95
    gamma: 0.99
    clip_param: 0.2
    entropy_coeff: 0.001
    train_batch_size: 1024
    sgd_minibatch_size: 128
    num_sgd_iter: 1
    num_workers: 4
    lr: 0.0003
    num_envs_per_worker: 16
    batch_mode: truncate_episodes
    rollout_fragment_length: 32
    num_gpus: 1
    model:
        fcnet_hiddens: [256, 256]
    no_done_at_end: true
    soft_horizon: true
